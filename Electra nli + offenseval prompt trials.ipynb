{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"secrets.json\", \"r\") as secrets_file:\n",
    "    secrets = json.load(secrets_file)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "electra_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"google/electra-large-discriminator\", normalization=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2ccc1741bd4ecf8aa7f1f38ffd235b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98e2373835948aeb6a2bd32c32317b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801316101c7c45c3a3752f45623ec9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51eab919b6fd47558d2b1800631a6cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c314671aeeb24c2087599661d963be3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57630d88c394761ab967ddef6c0dc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010c555aa9454d72810f2034c410ae72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83758fe8ca49472d9f91543fed19ce1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0a133166274643a7b62d39c8167539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bc12b7097243189e7bfb9c8b4422de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11916 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a437610d390343e1881376b6e8ed1be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1324 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc26c60e80a4c8691fed3fb4a351acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/860 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5b68f132f84220b4513bcdce78a2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5abca8930c4d5ca2932bd40279b92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28059643b534c36906fb9df082dc3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc10becf80b4b46ba6db351f5c138f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1498c9fa66c84c428e4271dad3aec9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4f471f4fbc48eb90000cd99de3d6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fb5f50303b4a448e60311e7d2e476c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc98e4cb28554880b37c467465e566ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdac0526f81f4461ab3ca910d310eadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cd277ce7d04998aa233cf44247c334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11916 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0519b7bac384473ab014715f33f7cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1324 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926bb6c6767049999700497e77bb8d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/860 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6bd27c30824aac9d7b22797b4fb2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0f1eb245644549832cf45d79b58802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2f2f3f356642e2a224a1463d237c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9741472965d746619035388c24307a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc3bc8c734945bfa349fcd627866de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d170a8ac5b5041698a04b0a71b4d75b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad26ad844ce411e88f1ec8d520df687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc065d02f62a4fe988b3b4e6618d617b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2029a23f80874aebbe3a714c81ff4e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d257b4221d694da9a6a0f1640b5e7ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11916 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802d8ce9338e4674ac25879e31fea33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1324 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e53e6f30a2140e6964aba810ff6b7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/860 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import load_tweeteval, indice2logits\n",
    "import pandas as pd\n",
    "\n",
    "hypotheses = [\n",
    "    \"This sentence contains profanity or a targeted offense.\",\n",
    "    \"This sentence contains insult, threat, profanity or swear words.\",\n",
    "    \"This sentence contains insult, threat, profanity, swear words or targeted offense.\",\n",
    "]\n",
    "\n",
    "offenseval_dataset_dicts = {\n",
    "    hypothesis: (\n",
    "        load_tweeteval()[\"offensive\"]\n",
    "        .map(\n",
    "            lambda rec: {\"labels\": (pd.Series(rec[\"labels\"]) * (-2) + 2).values},\n",
    "            batched=True,\n",
    "            batch_size=1024,\n",
    "        )\n",
    "        .map(\n",
    "            lambda rec: (indice2logits(rec[\"labels\"], 3)), batched=True, batch_size=1024\n",
    "        )\n",
    "        .rename_columns({\"labels\": \"label_categoricals\", \"label_logits\": \"labels\"})\n",
    "        .rename_columns({\"text\": \"premise\"})\n",
    "        .map(\n",
    "            lambda rec: {\"hypothesis\": len(rec[\"premise\"]) * [hypothesis]},\n",
    "            batched=True,\n",
    "            batch_size=1024,\n",
    "        )\n",
    "        .map(\n",
    "            lambda rec: electra_tokenizer(\n",
    "                rec[\"premise\"],\n",
    "                rec[\"hypothesis\"],\n",
    "                padding=\"longest\",\n",
    "                pad_to_multiple_of=8,\n",
    "                return_token_type_ids=True,\n",
    "                return_attention_mask=True,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    for hypothesis in hypotheses\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Using amp half precision backend\n",
      "The following columns in the training set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running training *****\n",
      "  Num examples = 11916\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 1395\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1395' max='1395' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1395/1395 56:00, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.446400</td>\n",
       "      <td>0.403205</td>\n",
       "      <td>0.766616</td>\n",
       "      <td>0.730446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>0.358493</td>\n",
       "      <td>0.777946</td>\n",
       "      <td>0.745929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.337694</td>\n",
       "      <td>0.777946</td>\n",
       "      <td>0.761262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.320290</td>\n",
       "      <td>0.787009</td>\n",
       "      <td>0.760295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.296700</td>\n",
       "      <td>0.308521</td>\n",
       "      <td>0.790030</td>\n",
       "      <td>0.765013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.305660</td>\n",
       "      <td>0.793051</td>\n",
       "      <td>0.765750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.307096</td>\n",
       "      <td>0.793807</td>\n",
       "      <td>0.766469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.277200</td>\n",
       "      <td>0.304263</td>\n",
       "      <td>0.790785</td>\n",
       "      <td>0.765729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.274500</td>\n",
       "      <td>0.298986</td>\n",
       "      <td>0.780967</td>\n",
       "      <td>0.759922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.270100</td>\n",
       "      <td>0.299368</td>\n",
       "      <td>0.786254</td>\n",
       "      <td>0.765370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.299122</td>\n",
       "      <td>0.790030</td>\n",
       "      <td>0.767999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.298888</td>\n",
       "      <td>0.785498</td>\n",
       "      <td>0.764425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.297657</td>\n",
       "      <td>0.793807</td>\n",
       "      <td>0.769112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.263400</td>\n",
       "      <td>0.297685</td>\n",
       "      <td>0.791541</td>\n",
       "      <td>0.767969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.298591</td>\n",
       "      <td>0.789275</td>\n",
       "      <td>0.767284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-93\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-93/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-93/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-93/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-93/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-186\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-186/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-186/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-186/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-186/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-279\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-279/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-279/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-279/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-279/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-372\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-372/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-372/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-372/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-372/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-465\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-465/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-465/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-465/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-465/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-558\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-558/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-558/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-558/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-558/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-651\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-651/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-651/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-651/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-651/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-744\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-744/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-744/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-744/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-744/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-837\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-837/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-837/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-837/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-837/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-930\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-930/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-930/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-930/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-930/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1023\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1116\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1209\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1302\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1395\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from outputs/electra-nli-efl-offenseval/checkpoint-1209 (score: 0.29765722155570984).\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from utils import trainer_compute_metrics\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=16,\n",
    "    output_dir=\"outputs/electra-nli-efl-offenseval\",\n",
    "    overwrite_output_dir=True,\n",
    "    dataloader_num_workers=4,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    remove_unused_columns=True,\n",
    "    eval_accumulation_steps=128,\n",
    "    optim=\"adamw_torch\",\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    gradient_checkpointing=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")\n",
    "\n",
    "datasets = offenseval_dataset_dicts[\n",
    "    \"This sentence contains profanity or a targeted offense.\"\n",
    "]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli\",\n",
    "        num_labels=3,\n",
    "    ),\n",
    "    tokenizer=electra_tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"val\"],\n",
    "    compute_metrics=trainer_compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_output = trainer.train()\n",
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 11916\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1764' max='1490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1490/1490 00:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 860\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('train', 'accuracy', 0.8404665995300437),\n",
       " ('train', 'f1', 0.8179708378918003),\n",
       " ('val', 'accuracy', 0.7938066465256798),\n",
       " ('val', 'f1', 0.7691121037734583),\n",
       " ('test', 'accuracy', 0.8558139534883721),\n",
       " ('test', 'f1', 0.8123209269910103)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_metrics, f1_macro, get_labels\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "results[\"This sentence contains profanity or a targeted offense.\"] = get_metrics(\n",
    "    lambda inputs: trainer.predict(inputs).predictions.argmax(axis=1),\n",
    "    datasets,\n",
    "    get_labels(datasets, \"label_categoricals\"),\n",
    "    [\"train\", \"val\", \"test\"],\n",
    "    {\"accuracy\": accuracy_score, \"f1\": f1_macro},\n",
    ")\n",
    "\n",
    "del trainer\n",
    "del trainer_output\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "results[\"This sentence contains profanity or a targeted offense.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli/resolve/main/config.json from cache at /home/chris-zeng/.cache/huggingface/transformers/767fab951e9d8c432dc3775f2943a5208b7e3f6975863a23aaeba306a1c5980e.3104f0cd2cbab9afd68c2c65670667c1b6c00aa3da4c65b894d38f853ed1eb71\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 1024,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli/resolve/main/pytorch_model.bin from cache at /home/chris-zeng/.cache/huggingface/transformers/9344f4058039030e7fa9899bee90c1134baefbee0c353c07f7e87d552e167f94.e6425238b58c11d46d8047b03a8fa1d7d4793e5cdbfb1724105c206e96f62291\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n",
      "Using amp half precision backend\n",
      "The following columns in the training set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running training *****\n",
      "  Num examples = 11916\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 1395\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1395' max='1395' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1395/1395 56:50, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.403364</td>\n",
       "      <td>0.768127</td>\n",
       "      <td>0.733207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.373000</td>\n",
       "      <td>0.358055</td>\n",
       "      <td>0.779456</td>\n",
       "      <td>0.742428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332900</td>\n",
       "      <td>0.348588</td>\n",
       "      <td>0.759819</td>\n",
       "      <td>0.746637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.318370</td>\n",
       "      <td>0.782477</td>\n",
       "      <td>0.755471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.308477</td>\n",
       "      <td>0.783233</td>\n",
       "      <td>0.755064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.304142</td>\n",
       "      <td>0.789275</td>\n",
       "      <td>0.760774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.304205</td>\n",
       "      <td>0.791541</td>\n",
       "      <td>0.764315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.279300</td>\n",
       "      <td>0.299098</td>\n",
       "      <td>0.788520</td>\n",
       "      <td>0.765355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.299009</td>\n",
       "      <td>0.785498</td>\n",
       "      <td>0.764190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.272700</td>\n",
       "      <td>0.299354</td>\n",
       "      <td>0.783988</td>\n",
       "      <td>0.764149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.269400</td>\n",
       "      <td>0.296966</td>\n",
       "      <td>0.788520</td>\n",
       "      <td>0.766330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>0.297147</td>\n",
       "      <td>0.787009</td>\n",
       "      <td>0.765142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>0.297626</td>\n",
       "      <td>0.797583</td>\n",
       "      <td>0.773466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.296626</td>\n",
       "      <td>0.790785</td>\n",
       "      <td>0.768475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.298324</td>\n",
       "      <td>0.787764</td>\n",
       "      <td>0.767029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-93\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-93/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-93/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-93/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-93/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-186\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-186/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-186/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-186/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-186/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-279\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-279/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-279/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-279/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-279/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-372\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-372/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-372/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-372/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-372/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-465\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-465/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-465/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-465/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-465/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-558\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-558/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-558/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-558/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-558/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-651\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-651/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-651/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-651/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-651/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-744\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-744/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-744/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-744/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-744/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-837\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-837/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-837/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-837/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-837/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-930\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-930/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-930/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-930/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-930/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1023\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1116\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1209\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1302\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1395\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from outputs/electra-nli-efl-offenseval/checkpoint-1302 (score: 0.29662564396858215).\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from utils import trainer_compute_metrics\n",
    "\n",
    "datasets = offenseval_dataset_dicts[\n",
    "    \"This sentence contains insult, threat, profanity or swear words.\"\n",
    "]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli\",\n",
    "        num_labels=3,\n",
    "    ),\n",
    "    tokenizer=electra_tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"val\"],\n",
    "    compute_metrics=trainer_compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_output = trainer.train()\n",
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 11916\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1764' max='1490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1490/1490 00:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 860\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('train', 'accuracy', 0.8402148371936892),\n",
       " ('train', 'f1', 0.8188765080715483),\n",
       " ('val', 'accuracy', 0.790785498489426),\n",
       " ('val', 'f1', 0.7684752107723531),\n",
       " ('test', 'accuracy', 0.8511627906976744),\n",
       " ('test', 'f1', 0.8068283917340521)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_metrics, f1_macro, get_labels\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "results[\"This sentence contains insult, threat, profanity or swear words.\"] = get_metrics(\n",
    "    lambda inputs: trainer.predict(inputs).predictions.argmax(axis=1),\n",
    "    datasets,\n",
    "    get_labels(datasets, \"label_categoricals\"),\n",
    "    [\"train\", \"val\", \"test\"],\n",
    "    {\"accuracy\": accuracy_score, \"f1\": f1_macro},\n",
    ")\n",
    "\n",
    "del trainer\n",
    "del trainer_output\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "results[\"This sentence contains insult, threat, profanity or swear words.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli/resolve/main/config.json from cache at /home/chris-zeng/.cache/huggingface/transformers/767fab951e9d8c432dc3775f2943a5208b7e3f6975863a23aaeba306a1c5980e.3104f0cd2cbab9afd68c2c65670667c1b6c00aa3da4c65b894d38f853ed1eb71\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 1024,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli/resolve/main/pytorch_model.bin from cache at /home/chris-zeng/.cache/huggingface/transformers/9344f4058039030e7fa9899bee90c1134baefbee0c353c07f7e87d552e167f94.e6425238b58c11d46d8047b03a8fa1d7d4793e5cdbfb1724105c206e96f62291\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n",
      "Using amp half precision backend\n",
      "Loading model from outputs/electra-nli-efl-offenseval/checkpoint-930).\n",
      "The following columns in the training set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running training *****\n",
      "  Num examples = 11916\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 1395\n",
      "  Continuing training from checkpoint, will skip to saved global_step\n",
      "  Continuing training from epoch 10\n",
      "  Continuing training from global step 930\n",
      "  Will skip the first 10 epochs then the first 0 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe301cbed63a42f690540bc8b049b8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1395' max='1395' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1395/1395 18:51, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.272200</td>\n",
       "      <td>0.299882</td>\n",
       "      <td>0.792296</td>\n",
       "      <td>0.769666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.267200</td>\n",
       "      <td>0.297811</td>\n",
       "      <td>0.795317</td>\n",
       "      <td>0.771307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.297389</td>\n",
       "      <td>0.791541</td>\n",
       "      <td>0.769431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>0.298355</td>\n",
       "      <td>0.792296</td>\n",
       "      <td>0.770855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.298506</td>\n",
       "      <td>0.786254</td>\n",
       "      <td>0.765602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1023\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1023/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1116\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1116/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1209\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1209/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1302\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1302/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval/checkpoint-1395\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/checkpoint-1395/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from outputs/electra-nli-efl-offenseval/checkpoint-1209 (score: 0.2973889708518982).\n",
      "Saving model checkpoint to outputs/electra-nli-efl-offenseval\n",
      "Configuration saved in outputs/electra-nli-efl-offenseval/config.json\n",
      "/home/chris-zeng/csci544-project/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in outputs/electra-nli-efl-offenseval/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/electra-nli-efl-offenseval/tokenizer_config.json\n",
      "Special tokens file saved in outputs/electra-nli-efl-offenseval/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from utils import trainer_compute_metrics\n",
    "\n",
    "datasets = offenseval_dataset_dicts[\n",
    "    \"This sentence contains insult, threat, profanity, swear words or targeted offense.\"\n",
    "]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli\",\n",
    "        num_labels=3,\n",
    "    ),\n",
    "    tokenizer=electra_tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"val\"],\n",
    "    compute_metrics=trainer_compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_output = trainer.train(resume_from_checkpoint=\"outputs/electra-nli-efl-offenseval/checkpoint-930\")\n",
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 11916\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1764' max='1490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1490/1490 00:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1324\n",
      "  Batch size = 8\n",
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: premise, hypothesis, label_categoricals.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 860\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('train', 'accuracy', 0.8379489761664988),\n",
       " ('train', 'f1', 0.8170080115175432),\n",
       " ('val', 'accuracy', 0.7915407854984894),\n",
       " ('val', 'f1', 0.7694305422001468),\n",
       " ('test', 'accuracy', 0.8534883720930233),\n",
       " ('test', 'f1', 0.811470447000856)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_metrics, f1_macro, get_labels\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "results[\"This sentence contains insult, threat, profanity, swear words or targeted offense.\"] = get_metrics(\n",
    "    lambda inputs: trainer.predict(inputs).predictions.argmax(axis=1),\n",
    "    datasets,\n",
    "    get_labels(datasets, \"label_categoricals\"),\n",
    "    [\"train\", \"val\", \"test\"],\n",
    "    {\"accuracy\": accuracy_score, \"f1\": f1_macro},\n",
    ")\n",
    "\n",
    "del trainer\n",
    "del trainer_output\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "results[\"This sentence contains insult, threat, profanity, swear words or targeted offense.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This sentence contains profanity or a targeted offense.': [('train',\n",
       "   'accuracy',\n",
       "   0.8404665995300437),\n",
       "  ('train', 'f1', 0.8179708378918003),\n",
       "  ('val', 'accuracy', 0.7938066465256798),\n",
       "  ('val', 'f1', 0.7691121037734583),\n",
       "  ('test', 'accuracy', 0.8558139534883721),\n",
       "  ('test', 'f1', 0.8123209269910103)],\n",
       " 'This sentence contains insult, threat, profanity or swear words.': [('train',\n",
       "   'accuracy',\n",
       "   0.8402148371936892),\n",
       "  ('train', 'f1', 0.8188765080715483),\n",
       "  ('val', 'accuracy', 0.790785498489426),\n",
       "  ('val', 'f1', 0.7684752107723531),\n",
       "  ('test', 'accuracy', 0.8511627906976744),\n",
       "  ('test', 'f1', 0.8068283917340521)],\n",
       " 'This sentence contains insult, threat, profanity, swear words or targeted offense.': [('train',\n",
       "   'accuracy',\n",
       "   0.8379489761664988),\n",
       "  ('train', 'f1', 0.8170080115175432),\n",
       "  ('val', 'accuracy', 0.7915407854984894),\n",
       "  ('val', 'f1', 0.7694305422001468),\n",
       "  ('test', 'accuracy', 0.8534883720930233),\n",
       "  ('test', 'f1', 0.811470447000856)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33f0e8d4354f47dbf330babecd1ea115412090f176c68201edfbe45cb7bacd91"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
