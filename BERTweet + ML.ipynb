{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_token = \"<HUB_TOKEN>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataframe = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\"./data/hateval2019_en_train.csv\"),\n",
    "        pd.read_csv(\"./data/hateval2019_en_dev.csv\"),\n",
    "        pd.read_csv(\"./data/hateval2019_en_test.csv\"),\n",
    "    ],\n",
    "    keys=[\"train\", \"dev\", \"test\"],\n",
    "    names=[\"split\", \"index\"],\n",
    ")\n",
    "\n",
    "datasets = DatasetDict(\n",
    "    {\n",
    "        split: Dataset.from_pandas(dataframe.loc[(split)])\n",
    "        for split in [\"train\", \"dev\", \"test\"]\n",
    "    }\n",
    ")\n",
    "datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"vinai/bertweet-covid19-base-cased\", normalization=True\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"vinai/bertweet-covid19-base-cased\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    pred_logits, labels_logits = eval_preds\n",
    "    preds = pred_logits.argmax(axis=1)\n",
    "    labels = labels_logits.argmax(axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def indice2logits(indice, num_classes):\n",
    "    indice = np.array(indice)\n",
    "    logits = np.zeros([len(indice), num_classes], dtype=float)\n",
    "    logits[np.arange(len(indice)), indice] = 1.0\n",
    "    return {\"label_logits\": logits}\n",
    "\n",
    "\n",
    "datasets = datasets.map(\n",
    "    lambda rec: tokenizer(\n",
    "        rec[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=192,\n",
    "        pad_to_multiple_of=8,\n",
    "        return_token_type_ids=True,\n",
    "        return_attention_mask=True,\n",
    "    ),\n",
    "    batched=True,\n",
    "    keep_in_memory=True,\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "datasets = datasets.map(\n",
    "    lambda rec: indice2logits(rec[\"HS\"], 2),\n",
    "    batched=True,\n",
    "    keep_in_memory=True,\n",
    ")\n",
    "\n",
    "datasets = datasets.rename_column(\"label_logits\", \"labels\")\n",
    "datasets = datasets.remove_columns([])\n",
    "datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs/bertweet\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=30,\n",
    "    logging_strategy=\"epoch\",\n",
    "    remove_unused_columns=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    eval_accumulation_steps=128,\n",
    "    optim=\"adamw_apex_fused\",\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    learning_rate=1e-6,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=True,\n",
    "    hub_strategy=\"all_checkpoints\",\n",
    "    hub_model_id=\"ChrisZeng/bertweet-base-cased-covid19-hateval\",\n",
    "    hub_token=hub_token,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"dev\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_output = trainer.train(\n",
    "    resume_from_checkpoint=True,\n",
    ")\n",
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"ChrisZeng/bertweet-base-cased-covid19-hateval\"\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"ChrisZeng/bertweet-base-cased-covid19-hateval\"\n",
    ")\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs/inference\",\n",
    "    overwrite_output_dir=True,\n",
    "    remove_unused_columns=True,\n",
    "    eval_accumulation_steps=128,\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args)\n",
    "\n",
    "\n",
    "preds = trainer.predict(datasets[\"test\"]).predictions.argmax(axis=1)\n",
    "labels = datasets[\"test\"][\"HS\"]\n",
    "\n",
    "{\n",
    "    \"accuracy\": accuracy_score(labels, preds),\n",
    "    \"f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33f0e8d4354f47dbf330babecd1ea115412090f176c68201edfbe45cb7bacd91"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
