{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "data_path = \"./data/toxic_spans\"\n",
    "filename = \"toxic_span_text_pairs.csv\"\n",
    "splits = [\"train\", \"eval\", \"test\"]\n",
    "\n",
    "dataset_dict = DatasetDict(\n",
    "    {\n",
    "        split: Dataset.from_pandas(\n",
    "            pd.read_csv(\n",
    "                data_path + \"/\" + filename.replace(\".csv\", \"_\" + split + \".csv\")\n",
    "            )\n",
    "        )\n",
    "        for split in splits\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def detox(tokenizer, model_buffered, batched_inputs):\n",
    "    input_sequence_buffered = tokenizer(\n",
    "        batched_inputs, padding=\"longest\", pad_to_multiple_of=8, return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output_sequence = model_buffered.generate(\n",
    "            input_ids=input_sequence_buffered[\"input_ids\"],\n",
    "            attention_mask=input_sequence_buffered[\"attention_mask\"],\n",
    "        )\n",
    "    del input_sequence_buffered\n",
    "    generated = [\n",
    "        \"<CSD>\" if len(generated) == 0 else generated\n",
    "        for generated in tokenizer.batch_decode(\n",
    "            output_sequence, skip_special_tokens=True\n",
    "        )\n",
    "    ]\n",
    "    return {\"generated\": generated}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "for model_name in [\"t5-base\", \"t5-v1_1-base\", \"bart-base\"]:\n",
    "    model_name = f\"ChrisZeng/{model_name}-detox\"\n",
    "\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model_buffered = model.to(\"cuda\")\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    dataset_dict = dataset_dict.map(\n",
    "        lambda rec: detox(tokenizer, model_buffered, rec[\"original\"]),\n",
    "        keep_in_memory=True,\n",
    "        batched=True,\n",
    "        batch_size=64,\n",
    "    ).rename_columns({\"generated\": f\"generated_{model_name}\"})\n",
    "\n",
    "    del model_buffered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class SentenceDetoxer(object):\n",
    "    def __init__(self, toxic_words):\n",
    "        self.replacements = {toxic_word: \"<CSD>\" for toxic_word in toxic_words}\n",
    "        self.pattern = \"|\".join(r\"\\b%s\\b\" % re.escape(s) for s in self.replacements)\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        return re.sub(\n",
    "            self.pattern, lambda match: self.replacements[match.group(0)], sentence\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hatebase = pd.read_csv(\"outputs/hatebase.csv\")\n",
    "hate_words = hatebase[hatebase[\"language\"] == \"English\"][\"word\"]\n",
    "hate_words = hate_words.str.split(\"(\").str[0].str.strip()\n",
    "toxic_words = pd.concat(\n",
    "    [hate_words, pd.read_csv(\"outputs/bad-words.csv\")[\"word\"],]\n",
    ").drop_duplicates()\n",
    "\n",
    "detoxer = SentenceDetoxer(toxic_words)\n",
    "\n",
    "dataset_dict = dataset_dict.map(\n",
    "    lambda record: {\"naive-detox\": detoxer(record[\"original\"])}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, dataset in dataset_dict.items():\n",
    "    dataset.to_pandas().to_csv(f\"outputs/generated_outputs_{split}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset_dict = DatasetDict(\n",
    "    {\n",
    "        split: Dataset.from_pandas(\n",
    "            pd.read_csv(f\"outputs/generated_outputs_{split}.csv\")\n",
    "        )\n",
    "        for split in [\"train\", \"eval\", \"test\"]\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ToxicScore(object):\n",
    "    def __init__(self, score_pipeline):\n",
    "        self.score_pipeline = score_pipeline\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return np.mean([result[0][\"score\"] for result in detoxify_pipeline(inputs)])\n",
    "\n",
    "\n",
    "detoxify_pipeline = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"unitary/toxic-bert\",\n",
    "    tokenizer=\"bert-base-uncased\",\n",
    "    function_to_apply=\"sigmoid\",\n",
    "    return_all_scores=True,\n",
    "    device=0,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "toxicscore = ToxicScore(detoxify_pipeline)\n",
    "\n",
    "from datasets import load_metric\n",
    "bertscore = load_metric(\"bertscore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/transformers/pipelines/base.py:996: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/transformers/pipelines/base.py:996: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/transformers/pipelines/base.py:996: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/transformers/pipelines/base.py:996: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/transformers/pipelines/base.py:996: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/transformers/pipelines/base.py:996: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/transformers/pipelines/base.py:996: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/transformers/pipelines/base.py:996: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">train</th>\n",
       "      <th>original</th>\n",
       "      <td>1.000005</td>\n",
       "      <td>0.634264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>censored</th>\n",
       "      <td>0.938402</td>\n",
       "      <td>0.119891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/t5-base-detox</th>\n",
       "      <td>0.904883</td>\n",
       "      <td>0.117076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/t5-v1_1-base-detox</th>\n",
       "      <td>0.909105</td>\n",
       "      <td>0.143238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/bart-base-detox</th>\n",
       "      <td>0.850838</td>\n",
       "      <td>0.077703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive-detox</th>\n",
       "      <td>0.978006</td>\n",
       "      <td>0.396886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">eval</th>\n",
       "      <th>original</th>\n",
       "      <td>1.000006</td>\n",
       "      <td>0.638489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>censored</th>\n",
       "      <td>0.939461</td>\n",
       "      <td>0.120043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/t5-base-detox</th>\n",
       "      <td>0.906586</td>\n",
       "      <td>0.120961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/t5-v1_1-base-detox</th>\n",
       "      <td>0.910119</td>\n",
       "      <td>0.143255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/bart-base-detox</th>\n",
       "      <td>0.852211</td>\n",
       "      <td>0.081079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive-detox</th>\n",
       "      <td>0.978564</td>\n",
       "      <td>0.391680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>original</th>\n",
       "      <td>1.000004</td>\n",
       "      <td>0.629271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>censored</th>\n",
       "      <td>0.939285</td>\n",
       "      <td>0.111152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/t5-base-detox</th>\n",
       "      <td>0.906485</td>\n",
       "      <td>0.112214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/t5-v1_1-base-detox</th>\n",
       "      <td>0.909313</td>\n",
       "      <td>0.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/bart-base-detox</th>\n",
       "      <td>0.855033</td>\n",
       "      <td>0.081856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive-detox</th>\n",
       "      <td>0.978401</td>\n",
       "      <td>0.386676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              similarity  toxicity\n",
       "split column                                                      \n",
       "train original                                  1.000005  0.634264\n",
       "      censored                                  0.938402  0.119891\n",
       "      generated_ChrisZeng/t5-base-detox         0.904883  0.117076\n",
       "      generated_ChrisZeng/t5-v1_1-base-detox    0.909105  0.143238\n",
       "      generated_ChrisZeng/bart-base-detox       0.850838  0.077703\n",
       "      naive-detox                               0.978006  0.396886\n",
       "eval  original                                  1.000006  0.638489\n",
       "      censored                                  0.939461  0.120043\n",
       "      generated_ChrisZeng/t5-base-detox         0.906586  0.120961\n",
       "      generated_ChrisZeng/t5-v1_1-base-detox    0.910119  0.143255\n",
       "      generated_ChrisZeng/bart-base-detox       0.852211  0.081079\n",
       "      naive-detox                               0.978564  0.391680\n",
       "test  original                                  1.000004  0.629271\n",
       "      censored                                  0.939285  0.111152\n",
       "      generated_ChrisZeng/t5-base-detox         0.906485  0.112214\n",
       "      generated_ChrisZeng/t5-v1_1-base-detox    0.909313  0.133200\n",
       "      generated_ChrisZeng/bart-base-detox       0.855033  0.081856\n",
       "      naive-detox                               0.978401  0.386676"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Pretty\n",
    "\n",
    "rouge = load_metric(\"rouge\")\n",
    "exact_match = load_metric(\"exact_match\")\n",
    "bertscore = load_metric(\"bertscore\")\n",
    "\n",
    "\n",
    "def compute_metrics(original, generated):\n",
    "    return {\n",
    "        \"similarity\": np.mean(\n",
    "            bertscore.compute(predictions=generated, references=original, lang=\"en\")[\n",
    "                \"f1\"\n",
    "            ]\n",
    "        ),\n",
    "        \"toxicity\": np.mean(toxicscore(generated)),\n",
    "    }\n",
    "\n",
    "\n",
    "metrics = pd.concat(\n",
    "    {\n",
    "        split: pd.concat(\n",
    "            pd.DataFrame(\n",
    "                compute_metrics(\n",
    "                    dataset_dict[split][\"original\"], dataset_dict[split][col]\n",
    "                ),\n",
    "                index=[col],\n",
    "            )\n",
    "            for col in dataset_dict[split].column_names\n",
    "        )\n",
    "        for split in dataset_dict.keys()\n",
    "    },\n",
    "    names=[\"split\", \"column\"],\n",
    ")\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris-zeng/csci544-project/apex-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>exact_match_rate</th>\n",
       "      <th>mean_bertscore_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">train</th>\n",
       "      <th>generated_ChrisZeng/t5-base-detox</th>\n",
       "      <td>0.600023</td>\n",
       "      <td>0.527782</td>\n",
       "      <td>0.596384</td>\n",
       "      <td>0.596429</td>\n",
       "      <td>0.028920</td>\n",
       "      <td>0.915085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/t5-v1_1-base-detox</th>\n",
       "      <td>0.573877</td>\n",
       "      <td>0.499064</td>\n",
       "      <td>0.569643</td>\n",
       "      <td>0.569903</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.912732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/bart-base-detox</th>\n",
       "      <td>0.326864</td>\n",
       "      <td>0.160558</td>\n",
       "      <td>0.323464</td>\n",
       "      <td>0.324277</td>\n",
       "      <td>0.051734</td>\n",
       "      <td>0.882190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive-detox</th>\n",
       "      <td>0.813105</td>\n",
       "      <td>0.742662</td>\n",
       "      <td>0.808225</td>\n",
       "      <td>0.808793</td>\n",
       "      <td>0.103583</td>\n",
       "      <td>0.948868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">eval</th>\n",
       "      <th>generated_ChrisZeng/t5-base-detox</th>\n",
       "      <td>0.604262</td>\n",
       "      <td>0.523416</td>\n",
       "      <td>0.599722</td>\n",
       "      <td>0.599935</td>\n",
       "      <td>0.020323</td>\n",
       "      <td>0.914312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/t5-v1_1-base-detox</th>\n",
       "      <td>0.584831</td>\n",
       "      <td>0.506420</td>\n",
       "      <td>0.580486</td>\n",
       "      <td>0.580810</td>\n",
       "      <td>0.080323</td>\n",
       "      <td>0.913919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/bart-base-detox</th>\n",
       "      <td>0.332699</td>\n",
       "      <td>0.166041</td>\n",
       "      <td>0.328492</td>\n",
       "      <td>0.329628</td>\n",
       "      <td>0.043871</td>\n",
       "      <td>0.882423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive-detox</th>\n",
       "      <td>0.817980</td>\n",
       "      <td>0.747777</td>\n",
       "      <td>0.812850</td>\n",
       "      <td>0.813122</td>\n",
       "      <td>0.109355</td>\n",
       "      <td>0.950081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">test</th>\n",
       "      <th>generated_ChrisZeng/t5-base-detox</th>\n",
       "      <td>0.593510</td>\n",
       "      <td>0.514044</td>\n",
       "      <td>0.589424</td>\n",
       "      <td>0.589320</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.913068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/t5-v1_1-base-detox</th>\n",
       "      <td>0.574478</td>\n",
       "      <td>0.496127</td>\n",
       "      <td>0.570753</td>\n",
       "      <td>0.570676</td>\n",
       "      <td>0.079839</td>\n",
       "      <td>0.912746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated_ChrisZeng/bart-base-detox</th>\n",
       "      <td>0.339363</td>\n",
       "      <td>0.176767</td>\n",
       "      <td>0.335875</td>\n",
       "      <td>0.336405</td>\n",
       "      <td>0.042473</td>\n",
       "      <td>0.883306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive-detox</th>\n",
       "      <td>0.813931</td>\n",
       "      <td>0.744925</td>\n",
       "      <td>0.809108</td>\n",
       "      <td>0.809765</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.949808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                rouge1    rouge2    rougeL  \\\n",
       "split column                                                                 \n",
       "train generated_ChrisZeng/t5-base-detox       0.600023  0.527782  0.596384   \n",
       "      generated_ChrisZeng/t5-v1_1-base-detox  0.573877  0.499064  0.569643   \n",
       "      generated_ChrisZeng/bart-base-detox     0.326864  0.160558  0.323464   \n",
       "      naive-detox                             0.813105  0.742662  0.808225   \n",
       "eval  generated_ChrisZeng/t5-base-detox       0.604262  0.523416  0.599722   \n",
       "      generated_ChrisZeng/t5-v1_1-base-detox  0.584831  0.506420  0.580486   \n",
       "      generated_ChrisZeng/bart-base-detox     0.332699  0.166041  0.328492   \n",
       "      naive-detox                             0.817980  0.747777  0.812850   \n",
       "test  generated_ChrisZeng/t5-base-detox       0.593510  0.514044  0.589424   \n",
       "      generated_ChrisZeng/t5-v1_1-base-detox  0.574478  0.496127  0.570753   \n",
       "      generated_ChrisZeng/bart-base-detox     0.339363  0.176767  0.335875   \n",
       "      naive-detox                             0.813931  0.744925  0.809108   \n",
       "\n",
       "                                              rougeLsum  exact_match_rate  \\\n",
       "split column                                                                \n",
       "train generated_ChrisZeng/t5-base-detox        0.596429          0.028920   \n",
       "      generated_ChrisZeng/t5-v1_1-base-detox   0.569903          0.091600   \n",
       "      generated_ChrisZeng/bart-base-detox      0.324277          0.051734   \n",
       "      naive-detox                              0.808793          0.103583   \n",
       "eval  generated_ChrisZeng/t5-base-detox        0.599935          0.020323   \n",
       "      generated_ChrisZeng/t5-v1_1-base-detox   0.580810          0.080323   \n",
       "      generated_ChrisZeng/bart-base-detox      0.329628          0.043871   \n",
       "      naive-detox                              0.813122          0.109355   \n",
       "test  generated_ChrisZeng/t5-base-detox        0.589320          0.016129   \n",
       "      generated_ChrisZeng/t5-v1_1-base-detox   0.570676          0.079839   \n",
       "      generated_ChrisZeng/bart-base-detox      0.336405          0.042473   \n",
       "      naive-detox                              0.809765          0.112903   \n",
       "\n",
       "                                              mean_bertscore_f1  \n",
       "split column                                                     \n",
       "train generated_ChrisZeng/t5-base-detox                0.915085  \n",
       "      generated_ChrisZeng/t5-v1_1-base-detox           0.912732  \n",
       "      generated_ChrisZeng/bart-base-detox              0.882190  \n",
       "      naive-detox                                      0.948868  \n",
       "eval  generated_ChrisZeng/t5-base-detox                0.914312  \n",
       "      generated_ChrisZeng/t5-v1_1-base-detox           0.913919  \n",
       "      generated_ChrisZeng/bart-base-detox              0.882423  \n",
       "      naive-detox                                      0.950081  \n",
       "test  generated_ChrisZeng/t5-base-detox                0.913068  \n",
       "      generated_ChrisZeng/t5-v1_1-base-detox           0.912746  \n",
       "      generated_ChrisZeng/bart-base-detox              0.883306  \n",
       "      naive-detox                                      0.949808  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Pretty\n",
    "\n",
    "rouge = load_metric(\"rouge\")\n",
    "exact_match = load_metric(\"exact_match\")\n",
    "bertscore = load_metric(\"bertscore\")\n",
    "\n",
    "\n",
    "def compute_metrics(predictions, targets):\n",
    "    return {\n",
    "        **{\n",
    "            key: value.mid.fmeasure\n",
    "            for key, value in rouge.compute(\n",
    "                predictions=predictions, references=targets\n",
    "            ).items()\n",
    "        },\n",
    "        \"exact_match_rate\": 0.01\n",
    "        * exact_match.compute(predictions=predictions, references=targets)[\n",
    "            \"exact_match\"\n",
    "        ],\n",
    "        \"mean_bertscore_f1\": np.mean(\n",
    "            bertscore.compute(predictions=predictions, references=targets, lang=\"en\")[\n",
    "                \"f1\"\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "metrics = pd.concat(\n",
    "    {\n",
    "        split: pd.concat(\n",
    "            pd.DataFrame(\n",
    "                compute_metrics(\n",
    "                    dataset_dict[split][col], dataset_dict[split][\"censored\"]\n",
    "                ),\n",
    "                index=[col],\n",
    "            )\n",
    "            for col in [\n",
    "                \"generated_ChrisZeng/t5-base-detox\",\n",
    "                \"generated_ChrisZeng/t5-v1_1-base-detox\",\n",
    "                \"generated_ChrisZeng/bart-base-detox\",\n",
    "                \"naive-detox\",\n",
    "            ]\n",
    "        )\n",
    "        for split in dataset_dict.keys()\n",
    "    },\n",
    "    names=[\"split\", \"column\"],\n",
    ")\n",
    "\n",
    "metrics\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bfe89fc0ce62c77ec618165bdab88a97265df2cf55337d24860c2391601a2f4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
